{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers datasets evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-11T16:45:12.852232Z","iopub.execute_input":"2024-05-11T16:45:12.852864Z","iopub.status.idle":"2024-05-11T16:45:27.758897Z","shell.execute_reply.started":"2024-05-11T16:45:12.852836Z","shell.execute_reply":"2024-05-11T16:45:27.757766Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m819.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:45:33.249745Z","iopub.execute_input":"2024-05-11T16:45:33.250106Z","iopub.status.idle":"2024-05-11T16:45:33.547210Z","shell.execute_reply.started":"2024-05-11T16:45:33.250076Z","shell.execute_reply":"2024-05-11T16:45:33.546315Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"241396b2677a4849bae3a3f5a395b7dd"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n\nsquad = load_dataset(\"squad\", split=\"train[:5000]\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:46:01.517476Z","iopub.execute_input":"2024-05-11T16:46:01.517870Z","iopub.status.idle":"2024-05-11T16:46:07.593317Z","shell.execute_reply.started":"2024-05-11T16:46:01.517841Z","shell.execute_reply":"2024-05-11T16:46:07.592360Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bb90bb920be4e36990516f0fb18e433"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 14.5M/14.5M [00:00<00:00, 45.5MB/s]\nDownloading data: 100%|██████████| 1.82M/1.82M [00:00<00:00, 13.8MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82b2634987434bcba83754e0d13ebb0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce0a5f6bce4544ebb84025ba13a2804a"}},"metadata":{}}]},{"cell_type":"code","source":"squad = squad.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:46:14.918980Z","iopub.execute_input":"2024-05-11T16:46:14.919851Z","iopub.status.idle":"2024-05-11T16:46:14.940915Z","shell.execute_reply.started":"2024-05-11T16:46:14.919817Z","shell.execute_reply":"2024-05-11T16:46:14.940115Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"squad[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:46:21.735380Z","iopub.execute_input":"2024-05-11T16:46:21.735959Z","iopub.status.idle":"2024-05-11T16:46:21.750310Z","shell.execute_reply.started":"2024-05-11T16:46:21.735930Z","shell.execute_reply":"2024-05-11T16:46:21.749381Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'id': '56cf9d81234ae51400d9be1f',\n 'title': 'New_York_City',\n 'context': \"Situated on one of the world's largest natural harbors, New York City consists of five boroughs, each of which is a separate county of New York State. The five boroughs – Brooklyn, Queens, Manhattan, the Bronx, and Staten Island – were consolidated into a single city in 1898. With a census-estimated 2014 population of 8,491,079 distributed over a land area of just 305 square miles (790 km2), New York is the most densely populated major city in the United States. As many as 800 languages are spoken in New York, making it the most linguistically diverse city in the world. By 2014 census estimates, the New York City metropolitan region remains by a significant margin the most populous in the United States, as defined by both the Metropolitan Statistical Area (20.1 million residents) and the Combined Statistical Area (23.6 million residents). In 2013, the MSA produced a gross metropolitan product (GMP) of nearly US$1.39 trillion, while in 2012, the CSA generated a GMP of over US$1.55 trillion, both ranking first nationally by a wide margin and behind the GDP of only twelve and eleven countries, respectively.\",\n 'question': 'How many languages are spoken by the people of New York City?',\n 'answers': {'text': ['800'], 'answer_start': [478]}}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:46:32.443930Z","iopub.execute_input":"2024-05-11T16:46:32.444280Z","iopub.status.idle":"2024-05-11T16:46:39.899228Z","shell.execute_reply.started":"2024-05-11T16:46:32.444253Z","shell.execute_reply":"2024-05-11T16:46:39.898254Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c252ea3038f848f4a311b3aa8ba5fb3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18da18d5ee2948c3979d8acfa476a2db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"103196acdd904c1297818f568d73d4d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"738785b3a0024821aabaed2451f5d43b"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=384,\n        truncation=\"only_second\",\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        answer = answers[i]\n        start_char = answer[\"answer_start\"][0]\n        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label it (0, 0)\n        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:46:46.437992Z","iopub.execute_input":"2024-05-11T16:46:46.438652Z","iopub.status.idle":"2024-05-11T16:46:46.450697Z","shell.execute_reply.started":"2024-05-11T16:46:46.438620Z","shell.execute_reply":"2024-05-11T16:46:46.449422Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:47:08.943923Z","iopub.execute_input":"2024-05-11T16:47:08.944845Z","iopub.status.idle":"2024-05-11T16:47:11.927547Z","shell.execute_reply.started":"2024-05-11T16:47:08.944811Z","shell.execute_reply":"2024-05-11T16:47:11.926542Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14e5e3c48579416bb2c2c266eb4a53f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f643ce905cc2494ebe0215a419f3ba1e"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator(return_tensors=\"tf\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:47:20.784145Z","iopub.execute_input":"2024-05-11T16:47:20.784537Z","iopub.status.idle":"2024-05-11T16:47:32.539192Z","shell.execute_reply.started":"2024-05-11T16:47:20.784507Z","shell.execute_reply":"2024-05-11T16:47:32.538417Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-05-11 16:47:23.509430: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-11 16:47:23.509526: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-11 16:47:23.700278: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import create_optimizer\n\nbatch_size = 16\nnum_epochs = 2\ntotal_train_steps = (len(tokenized_squad[\"train\"]) // batch_size) * num_epochs\noptimizer, schedule = create_optimizer(\n    init_lr=2e-5,\n    num_warmup_steps=0,\n    num_train_steps=total_train_steps,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:47:57.034567Z","iopub.execute_input":"2024-05-11T16:47:57.035772Z","iopub.status.idle":"2024-05-11T16:48:00.040341Z","shell.execute_reply.started":"2024-05-11T16:47:57.035738Z","shell.execute_reply":"2024-05-11T16:48:00.039523Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import TFAutoModelForQuestionAnswering\n\nmodel = TFAutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:48:05.438426Z","iopub.execute_input":"2024-05-11T16:48:05.438791Z","iopub.status.idle":"2024-05-11T16:48:07.705216Z","shell.execute_reply.started":"2024-05-11T16:48:05.438759Z","shell.execute_reply":"2024-05-11T16:48:07.704523Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef97edc2860f466ab2ec9673b5f3ef1f"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForQuestionAnswering: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n- This IS expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"tf_train_set = model.prepare_tf_dataset(\n    tokenized_squad[\"train\"],\n    shuffle=True,\n    batch_size=16,\n    collate_fn=data_collator,\n)\n\ntf_validation_set = model.prepare_tf_dataset(\n    tokenized_squad[\"test\"],\n    shuffle=False,\n    batch_size=16,\n    collate_fn=data_collator,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:48:21.127917Z","iopub.execute_input":"2024-05-11T16:48:21.128730Z","iopub.status.idle":"2024-05-11T16:48:21.682696Z","shell.execute_reply.started":"2024-05-11T16:48:21.128691Z","shell.execute_reply":"2024-05-11T16:48:21.681865Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nmodel.compile(optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:48:30.960189Z","iopub.execute_input":"2024-05-11T16:48:30.960549Z","iopub.status.idle":"2024-05-11T16:48:30.976889Z","shell.execute_reply.started":"2024-05-11T16:48:30.960522Z","shell.execute_reply":"2024-05-11T16:48:30.975967Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers.keras_callbacks import PushToHubCallback\n\ncallback = PushToHubCallback(\n    output_dir=\"my_awesome_qa_model\",\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:48:36.947503Z","iopub.execute_input":"2024-05-11T16:48:36.947912Z","iopub.status.idle":"2024-05-11T16:48:40.201885Z","shell.execute_reply.started":"2024-05-11T16:48:36.947883Z","shell.execute_reply":"2024-05-11T16:48:40.201038Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\nCloning https://huggingface.co/rohandagar/my_awesome_qa_model into local empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers.keras_callbacks import PushToHubCallback\n\ncallback = PushToHubCallback(\n    output_dir=\"my_awesome_qa_model\",\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:49:03.343418Z","iopub.execute_input":"2024-05-11T16:49:03.344240Z","iopub.status.idle":"2024-05-11T16:49:03.509683Z","shell.execute_reply.started":"2024-05-11T16:49:03.344209Z","shell.execute_reply":"2024-05-11T16:49:03.508899Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\n/kaggle/working/my_awesome_qa_model is already a clone of https://huggingface.co/rohandagar/my_awesome_qa_model. Make sure you pull the latest changes with `repo.git_pull()`.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:50:49.181208Z","iopub.execute_input":"2024-05-11T16:50:49.181874Z","iopub.status.idle":"2024-05-11T16:50:49.187060Z","shell.execute_reply.started":"2024-05-11T16:50:49.181842Z","shell.execute_reply":"2024-05-11T16:50:49.185976Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:50:58.630855Z","iopub.execute_input":"2024-05-11T16:50:58.631671Z","iopub.status.idle":"2024-05-11T17:00:38.660359Z","shell.execute_reply.started":"2024-05-11T16:50:58.631640Z","shell.execute_reply":"2024-05-11T17:00:38.659236Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/3\n250/250 [==============================] - 192s 770ms/step - loss: 3.2923 - val_loss: 2.1065\nEpoch 2/3\n250/250 [==============================] - 196s 785ms/step - loss: 1.7687 - val_loss: 1.8142\nEpoch 3/3\n250/250 [==============================] - 188s 753ms/step - loss: 1.5373 - val_loss: 1.8142\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7a8a784d8a00>"},"metadata":{}}]},{"cell_type":"code","source":"question = \"How many programming languages does BLOOM support?\"\ncontext = \"BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.\"","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:05.856048Z","iopub.execute_input":"2024-05-11T17:01:05.856926Z","iopub.status.idle":"2024-05-11T17:01:05.861128Z","shell.execute_reply.started":"2024-05-11T17:01:05.856893Z","shell.execute_reply":"2024-05-11T17:01:05.860161Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nquestion_answerer = pipeline(\"question-answering\", model=\"my_awesome_qa_model\")\nquestion_answerer(question=question, context=context)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:01:35.379504Z","iopub.execute_input":"2024-05-11T17:01:35.379872Z","iopub.status.idle":"2024-05-11T17:01:36.627552Z","shell.execute_reply.started":"2024-05-11T17:01:35.379846Z","shell.execute_reply":"2024-05-11T17:01:36.626553Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at my_awesome_qa_model were not used when initializing TFDistilBertForQuestionAnswering: ['dropout_19']\n- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at my_awesome_qa_model and are newly initialized: ['dropout_39']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'score': 0.14746111631393433,\n 'start': 10,\n 'end': 95,\n 'answer': '176 billion parameters and can generate text in 46 languages natural languages and 13'}"},"metadata":{}}]},{"cell_type":"code","source":"try:\n    # Save the model to the Kaggle output directory\n    question_answerer.model.save_pretrained(\"/kaggle/working/saved_model\")\n    print(\"Model saved successfully!\")\nexcept Exception as e:\n    print(\"Error while saving the model:\", e)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:13:32.252603Z","iopub.execute_input":"2024-05-11T17:13:32.253007Z","iopub.status.idle":"2024-05-11T17:13:33.151009Z","shell.execute_reply.started":"2024-05-11T17:13:32.252978Z","shell.execute_reply":"2024-05-11T17:13:33.150020Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Model saved successfully!\n","output_type":"stream"}]},{"cell_type":"code","source":"#to use mode from hugging ","metadata":{},"execution_count":null,"outputs":[]}]}